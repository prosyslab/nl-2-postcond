# Config for running the preprocessing script which transforms the raw llm-generated 
# postconditions into something usable with EvalPlus

# Should be postcondition or code
sampleType: postcondition 

# This is true if you are using a Hydra MULTIRUN command to preprocess multiple LLM_generation runs at once
multirun: false

# Path to where the raw llm samples are housed
samplesFolder: "llm_gen_outputs/2025-09-19/10-15-18"

# Indicating if it is an opensource model, as in our evaluation, StarChat required more aggressive preprocessing
# due to less standardization in model responses
opensourceModel: false

exp_name: ""